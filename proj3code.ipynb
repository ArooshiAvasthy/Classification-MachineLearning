{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load MNIST on Python 3.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from urllib import request\n",
    "import gzip\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import os\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm_notebook\n",
    "from keras.utils import np_utils\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading train-images-idx3-ubyte.gz...\n",
      "Downloading t10k-images-idx3-ubyte.gz...\n",
      "Downloading train-labels-idx1-ubyte.gz...\n",
      "Downloading t10k-labels-idx1-ubyte.gz...\n",
      "Download complete.\n",
      "Save complete.\n"
     ]
    }
   ],
   "source": [
    "#MNIST Data download and processing\n",
    "filename = [\n",
    "[\"training_images\",\"train-images-idx3-ubyte.gz\"],\n",
    "[\"test_images\",\"t10k-images-idx3-ubyte.gz\"],\n",
    "[\"training_labels\",\"train-labels-idx1-ubyte.gz\"],\n",
    "[\"test_labels\",\"t10k-labels-idx1-ubyte.gz\"]\n",
    "]\n",
    "\n",
    "def download_mnist():\n",
    "    base_url = \"http://yann.lecun.com/exdb/mnist/\"\n",
    "    for name in filename:\n",
    "        print(\"Downloading \"+name[1]+\"...\")\n",
    "        request.urlretrieve(base_url+name[1], name[1])\n",
    "    print(\"Download complete.\")\n",
    "\n",
    "def save_mnist():\n",
    "    mnist = {}\n",
    "    for name in filename[:2]:\n",
    "        with gzip.open(name[1], 'rb') as f:\n",
    "            mnist[name[0]] = np.frombuffer(f.read(), np.uint8, offset=16).reshape(-1,28*28)\n",
    "    for name in filename[-2:]:\n",
    "        with gzip.open(name[1], 'rb') as f:\n",
    "            mnist[name[0]] = np.frombuffer(f.read(), np.uint8, offset=8)\n",
    "    with open(\"mnist.pkl\", 'wb') as f:\n",
    "        pickle.dump(mnist,f)\n",
    "    print(\"Save complete.\")\n",
    "\n",
    "def init():\n",
    "    download_mnist()\n",
    "    save_mnist()\n",
    "\n",
    "def load():\n",
    "    with open(\"mnist.pkl\",'rb') as f:\n",
    "        mnist = pickle.load(f)\n",
    "        print(mnist.keys())\n",
    "    #return mnist[\"training_images\"], mnist[\"training_labels\"], mnist[\"test_images\"], mnist[\"test_labels\"]\n",
    "    return mnist\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    init()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load USPS on Python 3.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "USPSMat  = []\n",
    "USPSTar  = []\n",
    "curPath  = 'proj3_images/Numerals'\n",
    "savedImg = [] # why have u given a separate folder for test, we cnt figure out the target in that. should we just take some data from numerls?\n",
    "\n",
    "for j in range(0,10):\n",
    "    curFolderPath = curPath + '/' + str(j)\n",
    "    imgs =  os.listdir(curFolderPath)\n",
    "    for img in imgs:\n",
    "        curImg = curFolderPath + '/' + img\n",
    "        if curImg[-3:] == 'png':\n",
    "            img = Image.open(curImg,'r')\n",
    "            img = img.resize((28, 28))\n",
    "            savedImg = img\n",
    "            imgdata = (255-np.array(img.getdata()))/255\n",
    "            USPSMat.append(imgdata)\n",
    "            USPSTar.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['test_images', 'training_labels', 'test_labels', 'training_images'])\n"
     ]
    }
   ],
   "source": [
    "#MNIST Data\n",
    "MNist_Dataset = load()\n",
    "Mnist_TrainingData = MNist_Dataset[\"training_images\"][:50000]\n",
    "Mnist_TrainingTarget = MNist_Dataset[\"training_labels\"][:50000]\n",
    "\n",
    "#MNIST TestData\n",
    "Mnist_TestingData = MNist_Dataset[\"training_images\"][50000:60000]\n",
    "Mnist_TestingTarget = MNist_Dataset[\"training_labels\"][50000:60000]\n",
    "\n",
    "#USPS Data\n",
    "USPS_TestingData = pd.DataFrame(USPSMat)\n",
    "USPS_TargetData = pd.DataFrame(USPSTar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For MNIST Dataset\n",
      "Errors: 1089  Correct :8911\n",
      "Testing Accuracy: 89.11\n",
      "Confusion Matrix MNIST\n",
      "[[ 926    0    3    9    1   22   18    2    7    3]\n",
      " [   0 1014    2   11    0    4    3    6   22    2]\n",
      " [   5   24  746   70    6   14   32   22   69    2]\n",
      " [   1    1    6  952    1   32    3    5   19   10]\n",
      " [   5   15    5    3  847    3   29   13    7   56]\n",
      " [   9    2    4   46    4  802   22    5   20    1]\n",
      " [   5    2    2    0    3   18  933    0    4    0]\n",
      " [   6    4    1   17    4    2    0 1024    3   29]\n",
      " [   0   13    2   46    1   69   12   14  833   19]\n",
      " [   4    6    0   12   15   23    2   59    6  834]]\n",
      "For USPS Dataset\n",
      "Errors: 15143  Correct :4856\n",
      "Testing Accuracy: 24.281214060703036\n",
      "Confusion Matrix USPS\n",
      "[[317   6 367 320 108 261 169 318  21 113]\n",
      " [ 49 118 552 184 159 228 103 367 161  79]\n",
      " [114  78 848 160  24 365 237  72  69  32]\n",
      " [ 39  69 396 506  12 720  45  87  86  40]\n",
      " [ 57  56 211  57 569 249 119 429 158  95]\n",
      " [ 59  42 552 146  29 935 104  87  33  13]\n",
      " [144  30 615 107  24 510 466  66  24  14]\n",
      " [104  76 100 455  95 136  22 697 249  66]\n",
      " [155  51 170 474 145 510 110 153 182  50]\n",
      " [ 38  69 103 404 127 173  27 685 156 218]]\n"
     ]
    }
   ],
   "source": [
    "#Logistic regression\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "def init_weights(shape):\n",
    "    return tf.Variable(tf.random_normal(shape, stddev=0.01))\n",
    "\n",
    "\n",
    "def model(X, w):\n",
    "    return tf.matmul(X, w) # notice we use the same model as linear regression, this is because there is a baked in cost function which performs softmax and cross entropy\n",
    "\n",
    "#mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "trX, trY, teX, teY = Mnist_TrainingData, np_utils.to_categorical(np.array(Mnist_TrainingTarget),10), Mnist_TestingData, np_utils.to_categorical(np.array(Mnist_TestingTarget),10)\n",
    "\n",
    "X = tf.placeholder(\"float\", [None, 784]) # create symbolic variables\n",
    "Y = tf.placeholder(\"float\", [None, 10])\n",
    "\n",
    "w = init_weights([784, 10]) # like in linear regression, we need a shared variable weight matrix for logistic regression\n",
    "\n",
    "py_x = model(X, w)\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=py_x, labels=Y)) # compute mean cross entropy (softmax is applied internally)\n",
    "train_op = tf.train.GradientDescentOptimizer(0.05).minimize(cost) # construct optimizer\n",
    "predict_op = tf.argmax(py_x, 1) # at predict time, evaluate the argmax of the logistic regression\n",
    "\n",
    "# Launch the graph in a session\n",
    "with tf.Session() as sess:\n",
    "    # you need to initialize all variables\n",
    "    tf.global_variables_initializer().run()\n",
    "    for i in range(1000):\n",
    "        for start, end in zip(range(0, len(trX), 128), range(128, len(trX)+1, 128)):\n",
    "            #end = start + 128\n",
    "\n",
    "            sess.run(train_op, feed_dict={X: trX[start:end], Y: trY[start:end]})\n",
    " \n",
    "        training_accuracy = []\n",
    "        training_accuracy.append(np.mean(np.argmax(teY, axis=1) ==\n",
    "                         sess.run(predict_op, feed_dict={X: teX})))\n",
    "    predictedTestLabelMNIST = sess.run(predict_op, feed_dict={X: teX})\n",
    "    predictedTestLabelUSPS  = sess.run(predict_op, feed_dict={X: USPS_TestingData})\n",
    "#Testing The Model for MNIST\n",
    "    wrong   = 0\n",
    "    right   = 0\n",
    "\n",
    "\n",
    "    for i,j in zip(teY,predictedTestLabelMNIST):\n",
    "\n",
    "        if np.argmax(i) == j:\n",
    "            right = right + 1\n",
    "        else:\n",
    "            wrong = wrong + 1\n",
    "\n",
    "    print(\"For MNIST Dataset\")\n",
    "    print(\"Errors: \" + str(wrong), \" Correct :\" + str(right))\n",
    "\n",
    "    print(\"Testing Accuracy: \" + str(right/(right+wrong)*100))\n",
    "    print('Confusion Matrix MNIST')\n",
    "    print(confusion_matrix(Mnist_TestingTarget,predictedTestLabelMNIST))\n",
    "    \n",
    "#Testing The Model for USPS\n",
    "    wrong   = 0\n",
    "    right   = 0\n",
    "  \n",
    "    for i,j in zip(np_utils.to_categorical(np.array(USPS_TargetData),10),predictedTestLabelUSPS):\n",
    "\n",
    "        if np.argmax(i) == j:\n",
    "            right = right + 1\n",
    "        else:\n",
    "            wrong = wrong + 1\n",
    "\n",
    "    print(\"For USPS Dataset\")\n",
    "    print(\"Errors: \" + str(wrong), \" Correct :\" + str(right))\n",
    "\n",
    "    print(\"Testing Accuracy: \" + str(right/(right+wrong)*100))\n",
    "    print('Confusion Matrix USPS')\n",
    "    print(confusion_matrix(USPS_TargetData, predictedTestLabelUSPS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM:\n",
      "Accuracy USPS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aroos\\Anaconda3\\envs\\iris_2\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.00      0.00      0.00      2000\n",
      "    class 1       0.10      1.00      0.18      2000\n",
      "    class 2       0.00      0.00      0.00      1999\n",
      "    class 3       0.00      0.00      0.00      2000\n",
      "    class 4       0.00      0.00      0.00      2000\n",
      "    class 5       0.00      0.00      0.00      2000\n",
      "    class 6       0.00      0.00      0.00      2000\n",
      "    class 7       0.00      0.00      0.00      2000\n",
      "    class 8       0.00      0.00      0.00      2000\n",
      "    class 9       0.00      0.00      0.00      2000\n",
      "\n",
      "avg / total       0.01      0.10      0.02     19999\n",
      "\n",
      "Confusion Matrix USPS\n",
      "[[   0 2000    0    0    0    0    0    0    0    0]\n",
      " [   0 2000    0    0    0    0    0    0    0    0]\n",
      " [   0 1999    0    0    0    0    0    0    0    0]\n",
      " [   0 2000    0    0    0    0    0    0    0    0]\n",
      " [   0 2000    0    0    0    0    0    0    0    0]\n",
      " [   0 2000    0    0    0    0    0    0    0    0]\n",
      " [   0 2000    0    0    0    0    0    0    0    0]\n",
      " [   0 2000    0    0    0    0    0    0    0    0]\n",
      " [   0 2000    0    0    0    0    0    0    0    0]\n",
      " [   0 2000    0    0    0    0    0    0    0    0]]\n",
      "Accuracy MNIST\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      0.99      0.99       991\n",
      "    class 1       0.98      0.99      0.99      1064\n",
      "    class 2       0.98      0.97      0.98       990\n",
      "    class 3       0.97      0.98      0.97      1030\n",
      "    class 4       0.99      0.98      0.98       983\n",
      "    class 5       0.98      0.96      0.97       915\n",
      "    class 6       0.98      0.99      0.99       967\n",
      "    class 7       0.98      0.98      0.98      1090\n",
      "    class 8       0.97      0.97      0.97      1009\n",
      "    class 9       0.97      0.96      0.97       961\n",
      "\n",
      "avg / total       0.98      0.98      0.98     10000\n",
      "\n",
      "Confusion Matrix MNIST\n",
      "[[ 984    0    3    0    0    0    1    1    1    1]\n",
      " [   0 1057    0    1    0    0    3    1    2    0]\n",
      " [   5    3  965    1    1    1    3    6    5    0]\n",
      " [   1    1    2 1005    1    5    0    3    9    3]\n",
      " [   0    5    2    0  960    0    0    2    1   13]\n",
      " [   1    0    5    8    1  880   11    0    4    5]\n",
      " [   1    1    0    0    1    2  961    0    1    0]\n",
      " [   3    6    1    2    2    1    0 1073    0    2]\n",
      " [   2    3    4   11    0    6    4    2  975    2]\n",
      " [   4    4    1    9    8    2    0    7    2  924]]\n",
      "Random Forest:\n",
      "Accuracy USPS\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.13      0.06      0.08      2000\n",
      "    class 1       0.07      0.12      0.09      2000\n",
      "    class 2       0.11      0.02      0.03      1999\n",
      "    class 3       0.09      0.04      0.05      2000\n",
      "    class 4       0.20      0.20      0.20      2000\n",
      "    class 5       0.12      0.02      0.04      2000\n",
      "    class 6       0.11      0.03      0.04      2000\n",
      "    class 7       0.14      0.74      0.24      2000\n",
      "    class 8       0.18      0.00      0.00      2000\n",
      "    class 9       0.08      0.04      0.05      2000\n",
      "\n",
      "avg / total       0.12      0.13      0.08     19999\n",
      "\n",
      "Confusion Matrix USPS\n",
      "[[ 113  154   56  101  269   12  103 1143    0   49]\n",
      " [   3  244   23   20   14    0   17 1594    0   85]\n",
      " [ 116  595   40   20   30   19   49  974    2  154]\n",
      " [ 145  453   15   77  201   45   27  772    7  258]\n",
      " [  10  269   33   72  405  125   10  982    3   91]\n",
      " [ 145  381   19  128  305   46   78  842    1   55]\n",
      " [ 165  420   36  204  136   40   55  865    1   78]\n",
      " [  52  246   42   26   51    8   44 1489    0   42]\n",
      " [ 100  444   70  191  282   66   79  705    3   60]\n",
      " [  22  266   16   65  327   29   48 1151    0   76]]\n",
      "Accuracy MNIST\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.93      0.97      0.95       991\n",
      "    class 1       0.95      0.98      0.96      1064\n",
      "    class 2       0.91      0.94      0.92       990\n",
      "    class 3       0.88      0.91      0.90      1030\n",
      "    class 4       0.91      0.94      0.93       983\n",
      "    class 5       0.90      0.87      0.89       915\n",
      "    class 6       0.96      0.95      0.96       967\n",
      "    class 7       0.96      0.95      0.95      1090\n",
      "    class 8       0.93      0.85      0.89      1009\n",
      "    class 9       0.93      0.88      0.90       961\n",
      "\n",
      "avg / total       0.93      0.93      0.93     10000\n",
      "\n",
      "Confusion Matrix MNIST\n",
      "[[ 966    0    4    3    1    2    3    0    9    3]\n",
      " [   0 1042    6    4    0    1    3    4    3    1]\n",
      " [  11    4  929   11    6    3    4   13    7    2]\n",
      " [   7    7   23  940    3   25    1    7   11    6]\n",
      " [   6    5   11    2  922    4    5    2    8   18]\n",
      " [  19    5   10   44    6  799   13    0   12    7]\n",
      " [   6    7    4    2   11    8  923    0    5    1]\n",
      " [   3    9    9   11    9    0    2 1033    2   12]\n",
      " [  14   13   22   36   13   25    4    6  861   15]\n",
      " [  10    4    6   17   37   18    1   12   11  845]]\n"
     ]
    }
   ],
   "source": [
    "# SVM & RandomForest\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "X_train_MNIST, y_train_MNIST = Mnist_TrainingData, Mnist_TrainingTarget\n",
    "\n",
    "X_test_MNIST, y_test_MNIST = Mnist_TestingData, Mnist_TestingTarget\n",
    "X_test_USPS, y_test_USPS = USPS_TestingData, USPS_TargetData\n",
    "# SVM\n",
    "classifier1 = SVC(kernel='poly', C=3, gamma =0.05);\n",
    "classifier1.fit(X_train_MNIST, y_train_MNIST)\n",
    "predicted_SVM_USPS = classifier1.predict(X_test_USPS)\n",
    "predicted_SVM_MNIST = classifier1.predict(X_test_MNIST)\n",
    "target_names = ['class 0', 'class 1', 'class 2','class 3', 'class 4', 'class 5','class 6', 'class 7', 'class 8','class 9']\n",
    "\n",
    "# get the accuracy\n",
    "print(\"SVM:\")\n",
    "print(\"Accuracy USPS\")\n",
    "print(classification_report(y_test_USPS, predicted_SVM_USPS, target_names=target_names))\n",
    "print('Confusion Matrix USPS')\n",
    "print(confusion_matrix(y_test_USPS, predicted_SVM_USPS))\n",
    "\n",
    "print(\"Accuracy MNIST\")\n",
    "print(classification_report(y_test_MNIST, predicted_SVM_MNIST, target_names=target_names))\n",
    "print('Confusion Matrix MNIST')\n",
    "print(confusion_matrix(y_test_MNIST, predicted_SVM_MNIST))\n",
    "#print accuracy_score(y_test_MNIST, predicted_SVM_MNIST)\n",
    "\n",
    "\n",
    "#RandomForestClassifier\n",
    "classifier2 = RandomForestClassifier(n_estimators=5);#less number of estimator, inlcude more parameters\n",
    "classifier2.fit(X_train_MNIST, y_train_MNIST)\n",
    "predicted_USPS = classifier2.predict(X_test_USPS)\n",
    "predicted_MNIST = classifier2.predict(X_test_MNIST)\n",
    "\n",
    "# get the accuracy\n",
    "print(\"Random Forest:\")\n",
    "print(\"Accuracy USPS\")\n",
    "print(classification_report(y_test_USPS, predicted_USPS, target_names=target_names))\n",
    "print('Confusion Matrix USPS')\n",
    "print(confusion_matrix(y_test_USPS, predicted_USPS))\n",
    "\n",
    "print(\"Accuracy MNIST\")\n",
    "print(classification_report(y_test_MNIST, predicted_MNIST, target_names=target_names))\n",
    "print('Confusion Matrix MNIST')\n",
    "print(confusion_matrix(y_test_MNIST, predicted_MNIST))\n",
    "#############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST Dataset:\n",
      "accuracy:\n",
      "0.7553\n",
      "loss:\n",
      "0.632573749542\n",
      "USPS Dataset:\n",
      "accuracy:\n",
      "0.325466273305\n",
      "loss:\n",
      "2.4758614878\n"
     ]
    }
   ],
   "source": [
    "# Neural Network\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Activation\n",
    "from keras.models import Sequential\n",
    "\n",
    "x_train_Mnist = Mnist_TrainingData\n",
    "y_train_Mnist = Mnist_TrainingTarget\n",
    "x_test_Mnist = Mnist_TestingData\n",
    "y_test_Mnist = Mnist_TestingTarget\n",
    "x_test_USPS = USPS_TestingData\n",
    "y_test_USPS = USPS_TargetData\n",
    "num_classes=10\n",
    "\n",
    "y_train_Mnist = keras.utils.to_categorical(y_train_Mnist, num_classes)\n",
    "y_test_Mnist = keras.utils.to_categorical(y_test_Mnist, num_classes)\n",
    "y_test_USPS = keras.utils.to_categorical(y_test_USPS, num_classes)\n",
    "image_size = 784\n",
    "model = Sequential()\n",
    "model.add(Dense(units=250, input_shape=(image_size,)))\n",
    "model.add(Activation(tf.nn.softmax))\n",
    "model.add(Dense(units=num_classes))\n",
    "model.add(Activation(tf.nn.softmax))\n",
    "model.compile(optimizer='sgd', loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model.fit(x_train_Mnist, y_train_Mnist, batch_size=250, epochs=2000,verbose=False,validation_split=.1)\n",
    "#MNIST Testing\n",
    "loss,accuracy = model.evaluate(x_test_Mnist, y_test_Mnist, verbose=False)\n",
    "print(\"MNIST Dataset:\")\n",
    "print(\"accuracy:\")\n",
    "print(accuracy)\n",
    "print(\"loss:\")\n",
    "print(loss)\n",
    "#USPS Testing\n",
    "loss,accuracy = model.evaluate(x_test_USPS, y_test_USPS, verbose=False)\n",
    "print(\"USPS Dataset:\")\n",
    "print(\"accuracy:\")\n",
    "print(accuracy)\n",
    "print(\"loss:\")\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "import statistics \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#Logistic regression\n",
    "model1= LogisticRegression()\n",
    "model1.fit(Mnist_TrainingData, Mnist_TrainingTarget)\n",
    "pred1=model1.predict(USPS_TestingData)\n",
    "\n",
    "#RandomForest\n",
    "classifier1 = RandomForestClassifier(n_estimators=5);\n",
    "classifier1.fit(Mnist_TrainingData, Mnist_TrainingTarget)\n",
    "pred2 = classifier1.predict(USPS_TestingData)\n",
    "\n",
    "classifier1 = RandomForestClassifier(class_weight=None, criterion='gini',\n",
    "            max_depth=2, max_features='auto', max_leaf_nodes=None,n_estimators=3);\n",
    "classifier1.fit(Mnist_TrainingData, Mnist_TrainingTarget)\n",
    "pred3 = classifier1.predict(USPS_TestingData)\n",
    "\n",
    "#SVM\n",
    "classifier2 = SVC(kernel='poly', C=3);\n",
    "classifier2.fit(Mnist_TrainingData, Mnist_TrainingTarget)\n",
    "pred4 = classifier2.predict(USPS_TestingData)\n",
    "\n",
    "classifier2 = SVC(kernel='linear', C=3);\n",
    "classifier2.fit(Mnist_TrainingData, Mnist_TrainingTarget)\n",
    "pred5 = classifier2.predict(USPS_TestingData)\n",
    "\n",
    "#Neural Network\n",
    "model = Sequential()\n",
    "model.add(Dense(units=250, input_shape=(784,)))\n",
    "model.add(Activation(tf.nn.softmax))\n",
    "model.add(Dense(units=10))\n",
    "model.add(Activation(tf.nn.softmax))\n",
    "model.compile(optimizer='sgd', loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model.fit(Mnist_TrainingData, Mnist_TrainingTarget, batch_size=250, epochs=2000,verbose=False,validation_split=.1)\n",
    "pred6=model.predict(USPS_TestingData)\n",
    "\n",
    "final_pred = np.array([])\n",
    "for i in range(0,len(USPS_TestingData)):\n",
    "    final_pred = np.append(final_pred, statistics.mode([pred1[i], pred2[i], pred3[i], pred4[i], pred5[i], pred6[i]]))\n",
    "print(final_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
